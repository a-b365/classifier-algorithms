{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bcdfc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "\n",
    "# Third party library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c922dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLINDED_FILE_PATH = \"../datasets/TASK_2/TASK_2/blinded_test_set.csv\"\n",
    "blinded_test_data = pd.read_csv(BLINDED_FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c580961",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the csv file\n",
    "\n",
    "FILE_PATH = \"../datasets/TASK_2/TASK_2/train_set.csv\"\n",
    "train_data = pd.read_csv(FILE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b84bded7",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_PATH = \"../datasets/TASK_2/TASK_2/test_set.csv\"\n",
    "test_data = pd.read_csv(TEST_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd1d29c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASS  count\n",
       "0      0    191\n",
       "1      1    124"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data['CLASS'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea0380ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CLASS</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CLASS  count\n",
       "0      0     58\n",
       "1      1     42"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['CLASS'].value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6e22f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_data.drop(columns=[\"ID\", \"CLASS\"])\n",
    "y_test = test_data[\"CLASS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5a88b2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data.drop(columns=[\"ID\", \"CLASS\"])\n",
    "y_train = train_data[\"CLASS\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cbd4e6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3b2e939",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  count\n",
       "0      0    199\n",
       "1     23    116"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_per_row = X_train.isnull().sum(axis=1)\n",
    "missing_per_row.value_counts().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5756da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(4)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Count infinities\n",
    "np.isinf(X_train.to_numpy()).sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d35fbcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Feature_72    2\n",
       "Feature_90    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inf_mask = np.isinf(X_train)\n",
    "inf_summary = inf_mask.sum(axis=0)\n",
    "inf_summary[inf_summary > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e015a9a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_clean = X_train.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92099879",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b9b704a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>50</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>3215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      50  count\n",
       "0  False   3215\n",
       "1   True     23"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.iloc[50].isnull().value_counts().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "70cb93ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy=\"mean\")\n",
    "X_imputed = imputer.fit_transform(X_clean)\n",
    "X_test = imputer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbf43d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scalar = StandardScaler()\n",
    "X_scaled = scalar.fit_transform(X_imputed)\n",
    "X_test = scalar.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fca4f89b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.64016118e+04, 3.65589788e+04, 1.34217979e+04, ...,\n",
       "        2.85106703e+01, 3.79238104e+00, 1.12015343e-01], shape=(3238,)),\n",
       " array([5.73178001e+08, 5.74492580e+08, 2.72592504e+07, ...,\n",
       "        2.91915412e+00, 6.61509292e-02, 1.89172126e-03], shape=(3238,)))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scalar.mean_, scalar.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73ae3c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature_1</th>\n",
       "      <th>Feature_2</th>\n",
       "      <th>Feature_3</th>\n",
       "      <th>Feature_4</th>\n",
       "      <th>Feature_5</th>\n",
       "      <th>Feature_6</th>\n",
       "      <th>Feature_7</th>\n",
       "      <th>Feature_8</th>\n",
       "      <th>Feature_9</th>\n",
       "      <th>Feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature_3229</th>\n",
       "      <th>Feature_3230</th>\n",
       "      <th>Feature_3231</th>\n",
       "      <th>Feature_3232</th>\n",
       "      <th>Feature_3233</th>\n",
       "      <th>Feature_3234</th>\n",
       "      <th>Feature_3235</th>\n",
       "      <th>Feature_3236</th>\n",
       "      <th>Feature_3237</th>\n",
       "      <th>Feature_3238</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.756859</td>\n",
       "      <td>-0.756281</td>\n",
       "      <td>-0.768458</td>\n",
       "      <td>1.790937</td>\n",
       "      <td>-0.703377</td>\n",
       "      <td>-0.622357</td>\n",
       "      <td>0.757830</td>\n",
       "      <td>-0.722168</td>\n",
       "      <td>0.757830</td>\n",
       "      <td>0.038485</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.903318</td>\n",
       "      <td>-1.903318</td>\n",
       "      <td>-0.795461</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.386250</td>\n",
       "      <td>-1.156615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.208265</td>\n",
       "      <td>1.487482</td>\n",
       "      <td>-1.156615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.684660</td>\n",
       "      <td>-0.686690</td>\n",
       "      <td>-0.980408</td>\n",
       "      <td>0.279318</td>\n",
       "      <td>0.567037</td>\n",
       "      <td>0.393269</td>\n",
       "      <td>-0.768013</td>\n",
       "      <td>0.617284</td>\n",
       "      <td>-0.768013</td>\n",
       "      <td>-0.059407</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.133632</td>\n",
       "      <td>-0.133632</td>\n",
       "      <td>-0.683039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.309647</td>\n",
       "      <td>-0.493571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.337385</td>\n",
       "      <td>0.542650</td>\n",
       "      <td>-0.493571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.381832</td>\n",
       "      <td>-0.380581</td>\n",
       "      <td>-0.235997</td>\n",
       "      <td>0.738313</td>\n",
       "      <td>-0.658969</td>\n",
       "      <td>-0.592319</td>\n",
       "      <td>0.689108</td>\n",
       "      <td>-0.672790</td>\n",
       "      <td>0.689108</td>\n",
       "      <td>-0.062952</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.972867</td>\n",
       "      <td>-0.972867</td>\n",
       "      <td>-0.396858</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.308825</td>\n",
       "      <td>-0.995803</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.354606</td>\n",
       "      <td>1.137855</td>\n",
       "      <td>-0.995803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.231255</td>\n",
       "      <td>0.232764</td>\n",
       "      <td>0.851293</td>\n",
       "      <td>0.408853</td>\n",
       "      <td>-1.186714</td>\n",
       "      <td>-0.927422</td>\n",
       "      <td>1.599928</td>\n",
       "      <td>-1.272312</td>\n",
       "      <td>1.599928</td>\n",
       "      <td>-0.063502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.486524</td>\n",
       "      <td>-0.486524</td>\n",
       "      <td>0.283390</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.154057</td>\n",
       "      <td>-0.763600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.374634</td>\n",
       "      <td>0.852824</td>\n",
       "      <td>-0.763600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.203521</td>\n",
       "      <td>0.203601</td>\n",
       "      <td>0.171085</td>\n",
       "      <td>-0.825213</td>\n",
       "      <td>0.093786</td>\n",
       "      <td>-0.031715</td>\n",
       "      <td>-0.308667</td>\n",
       "      <td>0.138226</td>\n",
       "      <td>-0.308667</td>\n",
       "      <td>-0.058745</td>\n",
       "      <td>...</td>\n",
       "      <td>0.680798</td>\n",
       "      <td>0.680798</td>\n",
       "      <td>0.173152</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.084921</td>\n",
       "      <td>0.703383</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196797</td>\n",
       "      <td>-0.859371</td>\n",
       "      <td>0.703383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>0.433827</td>\n",
       "      <td>0.435696</td>\n",
       "      <td>0.886849</td>\n",
       "      <td>-0.217469</td>\n",
       "      <td>-0.847973</td>\n",
       "      <td>-0.717820</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>-0.884254</td>\n",
       "      <td>0.990873</td>\n",
       "      <td>-0.060837</td>\n",
       "      <td>...</td>\n",
       "      <td>0.202267</td>\n",
       "      <td>0.202267</td>\n",
       "      <td>0.498488</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.027807</td>\n",
       "      <td>-0.355315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.162030</td>\n",
       "      <td>0.397758</td>\n",
       "      <td>-0.355315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>-1.168752</td>\n",
       "      <td>-1.170949</td>\n",
       "      <td>-1.748648</td>\n",
       "      <td>1.717631</td>\n",
       "      <td>1.244825</td>\n",
       "      <td>1.018591</td>\n",
       "      <td>-1.401877</td>\n",
       "      <td>1.297774</td>\n",
       "      <td>-1.401877</td>\n",
       "      <td>-0.060507</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.901386</td>\n",
       "      <td>-1.901386</td>\n",
       "      <td>-1.207844</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.440121</td>\n",
       "      <td>-0.957524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.652483</td>\n",
       "      <td>1.190021</td>\n",
       "      <td>-0.957524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>0.035969</td>\n",
       "      <td>0.035381</td>\n",
       "      <td>0.101320</td>\n",
       "      <td>-0.395710</td>\n",
       "      <td>-0.196988</td>\n",
       "      <td>-0.259780</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>-0.169541</td>\n",
       "      <td>0.043164</td>\n",
       "      <td>-0.058273</td>\n",
       "      <td>...</td>\n",
       "      <td>0.271247</td>\n",
       "      <td>0.271247</td>\n",
       "      <td>0.120722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.091668</td>\n",
       "      <td>-0.222419</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.963045</td>\n",
       "      <td>0.088390</td>\n",
       "      <td>-0.222419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>-0.472817</td>\n",
       "      <td>-0.471784</td>\n",
       "      <td>-0.331835</td>\n",
       "      <td>1.032608</td>\n",
       "      <td>-0.739118</td>\n",
       "      <td>-0.646287</td>\n",
       "      <td>0.814087</td>\n",
       "      <td>-0.762044</td>\n",
       "      <td>0.814087</td>\n",
       "      <td>-0.061786</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.381913</td>\n",
       "      <td>-1.381913</td>\n",
       "      <td>-0.550115</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323534</td>\n",
       "      <td>-0.894995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.392094</td>\n",
       "      <td>1.023034</td>\n",
       "      <td>-0.894995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>0.690171</td>\n",
       "      <td>0.691657</td>\n",
       "      <td>1.219785</td>\n",
       "      <td>-0.402856</td>\n",
       "      <td>-0.902918</td>\n",
       "      <td>-0.753154</td>\n",
       "      <td>1.083367</td>\n",
       "      <td>-0.946384</td>\n",
       "      <td>1.083367</td>\n",
       "      <td>-0.058583</td>\n",
       "      <td>...</td>\n",
       "      <td>0.538947</td>\n",
       "      <td>0.538947</td>\n",
       "      <td>0.687035</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.134792</td>\n",
       "      <td>0.163421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689963</td>\n",
       "      <td>-0.104044</td>\n",
       "      <td>0.163421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>315 rows × 3238 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feature_1  Feature_2  Feature_3  Feature_4  Feature_5  Feature_6  \\\n",
       "0    -0.756859  -0.756281  -0.768458   1.790937  -0.703377  -0.622357   \n",
       "1    -0.684660  -0.686690  -0.980408   0.279318   0.567037   0.393269   \n",
       "2    -0.381832  -0.380581  -0.235997   0.738313  -0.658969  -0.592319   \n",
       "3     0.231255   0.232764   0.851293   0.408853  -1.186714  -0.927422   \n",
       "4     0.203521   0.203601   0.171085  -0.825213   0.093786  -0.031715   \n",
       "..         ...        ...        ...        ...        ...        ...   \n",
       "310   0.433827   0.435696   0.886849  -0.217469  -0.847973  -0.717820   \n",
       "311  -1.168752  -1.170949  -1.748648   1.717631   1.244825   1.018591   \n",
       "312   0.035969   0.035381   0.101320  -0.395710  -0.196988  -0.259780   \n",
       "313  -0.472817  -0.471784  -0.331835   1.032608  -0.739118  -0.646287   \n",
       "314   0.690171   0.691657   1.219785  -0.402856  -0.902918  -0.753154   \n",
       "\n",
       "     Feature_7  Feature_8  Feature_9  Feature_10  ...  Feature_3229  \\\n",
       "0     0.757830  -0.722168   0.757830    0.038485  ...     -1.903318   \n",
       "1    -0.768013   0.617284  -0.768013   -0.059407  ...     -0.133632   \n",
       "2     0.689108  -0.672790   0.689108   -0.062952  ...     -0.972867   \n",
       "3     1.599928  -1.272312   1.599928   -0.063502  ...     -0.486524   \n",
       "4    -0.308667   0.138226  -0.308667   -0.058745  ...      0.680798   \n",
       "..         ...        ...        ...         ...  ...           ...   \n",
       "310   0.990873  -0.884254   0.990873   -0.060837  ...      0.202267   \n",
       "311  -1.401877   1.297774  -1.401877   -0.060507  ...     -1.901386   \n",
       "312   0.043164  -0.169541   0.043164   -0.058273  ...      0.271247   \n",
       "313   0.814087  -0.762044   0.814087   -0.061786  ...     -1.381913   \n",
       "314   1.083367  -0.946384   1.083367   -0.058583  ...      0.538947   \n",
       "\n",
       "     Feature_3230  Feature_3231  Feature_3232  Feature_3233  Feature_3234  \\\n",
       "0       -1.903318     -0.795461           0.0     -0.386250     -1.156615   \n",
       "1       -0.133632     -0.683039           0.0     -0.309647     -0.493571   \n",
       "2       -0.972867     -0.396858           0.0     -0.308825     -0.995803   \n",
       "3       -0.486524      0.283390           0.0     -0.154057     -0.763600   \n",
       "4        0.680798      0.173152           0.0      0.084921      0.703383   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "310      0.202267      0.498488           0.0     -0.027807     -0.355315   \n",
       "311     -1.901386     -1.207844           0.0     -0.440121     -0.957524   \n",
       "312      0.271247      0.120722           0.0     -0.091668     -0.222419   \n",
       "313     -1.381913     -0.550115           0.0     -0.323534     -0.894995   \n",
       "314      0.538947      0.687035           0.0      0.134792      0.163421   \n",
       "\n",
       "     Feature_3235  Feature_3236  Feature_3237  Feature_3238  \n",
       "0             0.0     -0.208265      1.487482     -1.156615  \n",
       "1             0.0     -0.337385      0.542650     -0.493571  \n",
       "2             0.0     -0.354606      1.137855     -0.995803  \n",
       "3             0.0     -0.374634      0.852824     -0.763600  \n",
       "4             0.0      0.196797     -0.859371      0.703383  \n",
       "..            ...           ...           ...           ...  \n",
       "310           0.0      0.162030      0.397758     -0.355315  \n",
       "311           0.0      0.652483      1.190021     -0.957524  \n",
       "312           0.0     -0.963045      0.088390     -0.222419  \n",
       "313           0.0      0.392094      1.023034     -0.894995  \n",
       "314           0.0      0.689963     -0.104044      0.163421  \n",
       "\n",
       "[315 rows x 3238 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X_train.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X_train.columns)\n",
    "X_scaled_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b2d2ec4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64c67772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reduced from 3238 to 3123 features\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(threshold=1e-5)\n",
    "X_var = selector.fit_transform(X_scaled_df)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "\n",
    "print(f\"Reduced from {X_scaled_df.shape[1]} to {X_var.shape[1]} features\")\n",
    "\n",
    "selected_mask = selector.get_support()\n",
    "\n",
    "selected_features = [feature_columns[i] for i in range(len(selected_mask)) if selected_mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd6a5fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:111: UserWarning: Features [1719 1731 1733 1909 1910 1911 1912 1913 1914 1915 1916 1917 1918 1919\n",
      " 1920 1921 1922 1923 1924 1925 1926 1927 1928 1929 1930 1931 1932 1933\n",
      " 2109 2110 2111 2112 2113 2114 2115 2116 2117 2118 2119 2120 2121 2122\n",
      " 2123 2124 2125 2126 2127 2128 2129 2130 2131 2132 2133 2248 2249 2255\n",
      " 2259 2376 2377 2383 2387 2504 2505 2511 2515 2632 2633 2639 2640 2643\n",
      " 2758 2759 2760 2761 2762 2763 2764 2765 2767 2769 2771 2772 2773 2886\n",
      " 2887 2888 2889 2890 2891 2892 2893 2895 2897 2899 2900 2901 2937 2938\n",
      " 2939 2940 2941 2977 2978 2979 2980 2981 3096 3097 3103 3106 3224 3225\n",
      " 3231 3234] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "d:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "selector = SelectKBest(score_func=f_classif, k=100)  # Try k=100 to start\n",
    "\n",
    "X_kbest = selector.fit_transform(X_scaled_df, y_train)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "# You can also get the selected column names if needed\n",
    "selected_mask = selector.get_support()\n",
    "\n",
    "selected_k_features = [feature_columns[i] for i in range(len(selected_mask)) if selected_mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bf41d014",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m estimator = RandomForestClassifier(n_estimators=\u001b[32m50\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m      5\u001b[39m feature_selector = RFE(estimator=estimator, n_features_to_select=\u001b[32m100\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m X_kbest = \u001b[43mfeature_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_scaled_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# y = your target column (CLASS)\u001b[39;00m\n\u001b[32m      7\u001b[39m X_test = feature_selector.transform(X_test)\n\u001b[32m      9\u001b[39m selected_mask = feature_selector.get_support()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\base.py:921\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:276\u001b[39m, in \u001b[36mRFE.fit\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    274\u001b[39m     routed_params = Bunch(estimator=Bunch(fit=fit_params))\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\feature_selection\\_rfe.py:332\u001b[39m, in \u001b[36mRFE._fit\u001b[39m\u001b[34m(self, X, y, step_score, **fit_params)\u001b[39m\n\u001b[32m    329\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose > \u001b[32m0\u001b[39m:\n\u001b[32m    330\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mFitting estimator with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m features.\u001b[39m\u001b[33m\"\u001b[39m % np.sum(support_))\n\u001b[32m--> \u001b[39m\u001b[32m332\u001b[39m \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[38;5;66;03m# Get importance and rank them\u001b[39;00m\n\u001b[32m    335\u001b[39m importances = _get_feature_importances(\n\u001b[32m    336\u001b[39m     estimator,\n\u001b[32m    337\u001b[39m     \u001b[38;5;28mself\u001b[39m.importance_getter,\n\u001b[32m    338\u001b[39m     transform_func=\u001b[33m\"\u001b[39m\u001b[33msquare\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    339\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:487\u001b[39m, in \u001b[36mBaseForest.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    476\u001b[39m trees = [\n\u001b[32m    477\u001b[39m     \u001b[38;5;28mself\u001b[39m._make_estimator(append=\u001b[38;5;28;01mFalse\u001b[39;00m, random_state=random_state)\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_more_estimators)\n\u001b[32m    479\u001b[39m ]\n\u001b[32m    481\u001b[39m \u001b[38;5;66;03m# Parallel loop: we prefer the threading backend as the Cython code\u001b[39;00m\n\u001b[32m    482\u001b[39m \u001b[38;5;66;03m# for fitting the trees is internally releasing the Python GIL\u001b[39;00m\n\u001b[32m    483\u001b[39m \u001b[38;5;66;03m# making threading more efficient than multiprocessing in\u001b[39;00m\n\u001b[32m    484\u001b[39m \u001b[38;5;66;03m# that case. However, for joblib 0.12+ we respect any\u001b[39;00m\n\u001b[32m    485\u001b[39m \u001b[38;5;66;03m# parallel_backend contexts set at a higher level,\u001b[39;00m\n\u001b[32m    486\u001b[39m \u001b[38;5;66;03m# since correctness does not rely on using threads.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m487\u001b[39m trees = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    489\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_parallel_build_trees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    500\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    501\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    502\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_samples_bootstrap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    503\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    505\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrees\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    506\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    508\u001b[39m \u001b[38;5;66;03m# Collect newly grown trees\u001b[39;00m\n\u001b[32m    509\u001b[39m \u001b[38;5;28mself\u001b[39m.estimators_.extend(trees)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1986\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1984\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1985\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1986\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1988\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1989\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1990\u001b[39m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1991\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1992\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1993\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\joblib\\parallel.py:1914\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1912\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1913\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1914\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1915\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1916\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:189\u001b[39m, in \u001b[36m_parallel_build_trees\u001b[39m\u001b[34m(tree, bootstrap, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01melif\u001b[39;00m class_weight == \u001b[33m\"\u001b[39m\u001b[33mbalanced_subsample\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    187\u001b[39m         curr_sample_weight *= compute_sample_weight(\u001b[33m\"\u001b[39m\u001b[33mbalanced\u001b[39m\u001b[33m\"\u001b[39m, y, indices=indices)\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[43mtree\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_fit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcurr_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    197\u001b[39m     tree._fit(\n\u001b[32m    198\u001b[39m         X,\n\u001b[32m    199\u001b[39m         y,\n\u001b[32m   (...)\u001b[39m\u001b[32m    202\u001b[39m         missing_values_in_feature_mask=missing_values_in_feature_mask,\n\u001b[32m    203\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\classifier-algorithms\\.venv\\Lib\\site-packages\\sklearn\\tree\\_classes.py:472\u001b[39m, in \u001b[36mBaseDecisionTree._fit\u001b[39m\u001b[34m(self, X, y, sample_weight, check_input, missing_values_in_feature_mask)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    462\u001b[39m     builder = BestFirstTreeBuilder(\n\u001b[32m    463\u001b[39m         splitter,\n\u001b[32m    464\u001b[39m         min_samples_split,\n\u001b[32m   (...)\u001b[39m\u001b[32m    469\u001b[39m         \u001b[38;5;28mself\u001b[39m.min_impurity_decrease,\n\u001b[32m    470\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtree_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmissing_values_in_feature_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.n_outputs_ == \u001b[32m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m is_classifier(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    475\u001b[39m     \u001b[38;5;28mself\u001b[39m.n_classes_ = \u001b[38;5;28mself\u001b[39m.n_classes_[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "feature_selector = RFE(estimator=estimator, n_features_to_select=100)\n",
    "X_kbest = feature_selector.fit_transform(X_scaled_df, y_train)  # y = your target column (CLASS)\n",
    "X_test = feature_selector.transform(X_test)\n",
    "\n",
    "selected_mask = feature_selector.get_support()\n",
    "selected_rfe_features = [feature_columns[i] for i in range(len(selected_mask)) if selected_mask[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7d0d955d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.48108137,  1.31325536, -1.52203587, ..., -0.34722282,\n",
       "        -0.88939853,  0.84372025],\n",
       "       [ 0.57166613,  0.37893616, -0.80669617, ..., -0.18927466,\n",
       "        -0.70589303,  1.82328967],\n",
       "       [-0.6671397 , -0.59787158,  0.70165661, ..., -0.47183225,\n",
       "        -0.09471213,  0.17241383],\n",
       "       ...,\n",
       "       [-0.83417749, -0.70886649,  0.96800111, ..., -0.1918633 ,\n",
       "         0.34321402, -0.85403222],\n",
       "       [-0.14947274, -0.22350309, -0.01692491, ..., -0.16057634,\n",
       "        -0.27720937, -0.03273799],\n",
       "       [-0.08795304, -0.17595864, -0.09316438, ...,  1.14720734,\n",
       "         0.73039048, -0.47027103]], shape=(100, 919))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5579810",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "estimator = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "selector = SelectFromModel(estimator, prefit=False)\n",
    "\n",
    "X_kbest = selector.fit_transform(X_scaled_df, y_train)  # y = your target column (CLASS)\n",
    "X_test = selector.transform(X_test)\n",
    "\n",
    "\n",
    "selected_mask = selector.get_support()\n",
    "selected_rfe_features = [feature_columns[i] for i in range(len(selected_mask)) if selected_mask[i]]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "32570687",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_kbest_df = pd.DataFrame(X_kbest, columns=selected_rfe_features)\n",
    "X_test = pd.DataFrame(X_test, columns=selected_rfe_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "811491dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "models_config = {\n",
    "\n",
    "    'Logistic Regression': {\n",
    "\n",
    "        'model': LogisticRegression(random_state=42, max_iter=1000),\n",
    "        'params': {\n",
    "            'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga']\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'Random Forest': {\n",
    "\n",
    "        'model': RandomForestClassifier(random_state=42, n_estimators=100),\n",
    "        'params':{\n",
    "            'n_estimators': [50, 100, 200],\n",
    "            'max_depth': [None, 10, 20, 30],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    'SVM': {\n",
    "\n",
    "        'model': SVC(random_state=42, probability=True),\n",
    "        'params': {\n",
    "            'C': [0.1, 1, 10, 100],\n",
    "            'gamma': ['scale', 'auto', 0.001, 0.01, 0.1, 1],\n",
    "            'kernel': ['rbf', 'linear']\n",
    "        }\n",
    "\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48ee6124",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Best CV Score: 0.6508\n",
      "Best Parameters: {'C': 0.001, 'penalty': 'l2', 'solver': 'liblinear'}\n",
      "Training Random Forest...\n",
      "Best CV Score: 0.6444\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Training SVM...\n",
      "Best CV Score: 0.6222\n",
      "Best Parameters: {'C': 1, 'gamma': 'auto', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "models = dict()\n",
    "\n",
    "for name, config in models_config.items():\n",
    "    print(f\"Training {name}...\")\n",
    "\n",
    "    grid_search = GridSearchCV(estimator=config['model'], param_grid=config['params'], cv=cv, n_jobs=-1, scoring='accuracy', verbose=0)\n",
    "    grid_search.fit(X_kbest_df, y_train)\n",
    "    models[name] = {\n",
    "        'model': grid_search.best_estimator_,\n",
    "        'best_params': grid_search.best_params_,\n",
    "        'cv_score': grid_search.best_score_\n",
    "    }    \n",
    "    print(f\"Best CV Score: {grid_search.best_score_:.4f}\")\n",
    "    print(f\"Best Parameters: {grid_search.best_params_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e2cafb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression:\n",
      "Test Accuracy: 0.5900\n",
      "CV Score: 0.6508\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.60      0.63        58\n",
      "           1       0.51      0.57      0.54        42\n",
      "\n",
      "    accuracy                           0.59       100\n",
      "   macro avg       0.59      0.59      0.58       100\n",
      "weighted avg       0.60      0.59      0.59       100\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Test Accuracy: 0.6300\n",
      "CV Score: 0.6444\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.79      0.71        58\n",
      "           1       0.59      0.40      0.48        42\n",
      "\n",
      "    accuracy                           0.63       100\n",
      "   macro avg       0.62      0.60      0.60       100\n",
      "weighted avg       0.62      0.63      0.61       100\n",
      "\n",
      "\n",
      "SVM:\n",
      "Test Accuracy: 0.6300\n",
      "CV Score: 0.6222\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.88      0.73        58\n",
      "           1       0.63      0.29      0.39        42\n",
      "\n",
      "    accuracy                           0.63       100\n",
      "   macro avg       0.63      0.58      0.56       100\n",
      "weighted avg       0.63      0.63      0.59       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model_info in models.items():\n",
    "    model = model_info['model']\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1] if hasattr(model, 'predict_proba') else None\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    results[name] = {\n",
    "\n",
    "        'accuracy': accuracy,\n",
    "        'cv_score': model_info['cv_score'],\n",
    "        'predictions': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"CV Score: {model_info['cv_score']:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5e53433b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[48 10]\n",
      " [26 16]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.83      0.73        58\n",
      "           1       0.62      0.38      0.47        42\n",
      "\n",
      "    accuracy                           0.64       100\n",
      "   macro avg       0.63      0.60      0.60       100\n",
      "weighted avg       0.63      0.64      0.62       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf_rf = RandomForestClassifier(n_estimators=50, random_state=42, max_depth= 10, min_samples_leaf= 2, min_samples_split= 5)\n",
    "clf_rf.fit(X_kbest_df, y_train)\n",
    "\n",
    "y_pred_rf = clf_rf.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb9c72a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
